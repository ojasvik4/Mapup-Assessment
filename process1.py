# -*- coding: utf-8 -*-
"""Process1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yoa5pPaH3lmqufXXjaCLDW6e7a3t9dU3

**Process 1: Extracting trips from GPS Data**
"""

import pandas as pd
import json
import os

df =  pd.read_parquet('/content/raw_data.parquet')
print(df)

df.to_csv('/content/raw_data.parquet.csv')

import csv
from datetime import datetime, timedelta

def identify_trips(timestamps, time_threshold_hours=7):
    trips = []
    current_trip = [timestamps[0]]

    for i in range(1, len(timestamps)):
        time_difference = timestamps[i] - timestamps[i-1]

        if time_difference.total_seconds() / 3600 > time_threshold_hours:
            # Start a new trip
            trips.append(current_trip)
            current_trip = [timestamps[i]]
        else:
            # Continue the current trip
            current_trip.append(timestamps[i])

    # Add the last trip
    trips.append(current_trip)

    return trips

def save_trip_to_csv(trip, unit, trip_number):
    filename = f'{unit}_{trip_number}.csv'
    with open(filename, 'w', newline='') as csvfile:
        fieldnames = ['latitude', 'longitude', 'timestamp']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()

        for timestamp in trip:
            # Replace this with your actual latitude, longitude, and timestamp values
            latitude = 0.0
            longitude = 0.0
            timestamp_str = timestamp.strftime('%Y-%m-%dT%H:%M:%SZ')

            writer.writerow({'latitude': latitude, 'longitude': longitude, 'timestamp': timestamp_str})

# Example usage:
timestamps = [
    datetime(2023, 1, 1, 8, 0),
    datetime(2023, 1, 1, 10, 0),
    datetime(2023, 1, 1, 18, 0),
    datetime(2023, 1, 1, 23, 0),
    datetime(2023, 1, 2, 9, 0),
    datetime(2023, 1, 2, 12, 0),
]

time_threshold_hours = 7
trips = identify_trips(timestamps, time_threshold_hours)

unit = "your_unit"  # Replace with your actual unit name

# Save each trip to a separate CSV file
for i, trip in enumerate(trips):
    save_trip_to_csv(trip, unit, i)

import argparse
import pandas as pd
from datetime import datetime, timedelta
import csv
import os

def identify_trips(timestamps, time_threshold_hours=7):
    trips = []
    current_trip = [timestamps[0]]

    for i in range(1, len(timestamps)):
        time_difference = timestamps[i] - timestamps[i-1]

        if time_difference.total_seconds() / 3600 > time_threshold_hours:
            # Start a new trip
            trips.append(current_trip)
            current_trip = [timestamps[i]]
        else:
            # Continue the current trip
            current_trip.append(timestamps[i])

    # Add the last trip
    trips.append(current_trip)

def save_trip_to_csv(trip, unit, trip_number, output_dir):
    filename = os.path.join(output_dir, f'{unit}_{trip_number}.csv')
    with open(filename, 'w', newline='') as csvfile:
        fieldnames = ['latitude', 'longitude', 'timestamp']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()

        for timestamp in trip:
            # Replace this with your actual latitude, longitude, and timestamp values
            latitude = 0.0
            longitude = 0.0
            timestamp_str = timestamp.strftime('%Y-%m-%dT%H:%M:%SZ')

            writer.writerow({'latitude': latitude, 'longitude': longitude, 'timestamp': timestamp_str})
def process_parquet(parquet_path, output_dir):
    # Read the Parquet file into a Pandas DataFrame
    df = pd.read_parquet(parquet_path)

    # Assuming 'timestamp' is a column in the DataFrame containing timestamps
    timestamps = pd.to_datetime(df['timestamp'])

    # Identify trips
    trips = identify_trips(timestamps)

    unit = os.path.splitext(os.path.basename(parquet_path))[0]  # Use the parquet file name as the unit name

    # Save each trip to a separate CSV file
    for i, trip in enumerate(trips):
        save_trip_to_csv(trip, unit, i, output_dir)

"""**Process 2: Uploading GPS tracks to TollGuru API**"""

import requests

def upload_gps_tracks(api_key, vehicle, csv_file_path):
    # API endpoint URL
    api_url = "https://api.tollguru.com/v1/gps-tracks-csv-upload"

    # Set up headers with API key
    headers = {
        "Content-Type": "application/octet-stream",
        "x-api-key": api_key,
    }

    # Read the binary content of the CSV file
    with open(csv_file_path, "rb") as file:
        csv_content = file.read()

    # Set up payload with vehicle information and CSV content
    payload = {
        "vehicle": vehicle,
    }

    # Make a POST request to the API
    response = requests.post(api_url, headers=headers, params=payload, data=csv_content)

    # Check if the request was successful (status code 200)
    if response.status_code == 200:
        # Parse and print the JSON response
        json_response = response.json()
        print("Toll information:", json_response)
    else:
        print(f"Error: {response.status_code} - {response.text}")

api_key = "osrm"  # Replace with your TollGuru API key
vehicle = "5AxlesTruck"  # Replace with your vehicle type
csv_file_path = "/content/raw_data.parquet.csv"  # Replace with the path to your binary CSV file

upload_gps_tracks(api_key, vehicle, csv_file_path)

api_key = "osrm"  # Replace with your TollGuru API key
vehicle = "5AxlesTruck"  # Replace with your vehicle type
csv_file_path = "/2000_0.json"

api_key = "osrm"  # Replace with your TollGuru API key
vehicle = "5AxlesTruck"  # Replace with your vehicle type
csv_file_path = "/2000_1.json"

"""**Process 3: Extracting Toll Information from JSON Files**"""

import os
import json

def process_toll_information(input_directory):
    # Check if the input directory exists
    if not os.path.exists(input_directory):
        print(f"Error: The specified directory '{input_directory}' does not exist.")
        return

    # Process each file in the input directory
    for filename in os.listdir(input_directory):
        # Check if the file has a JSON extension
        if filename.endswith(".json"):
            file_path = os.path.join(input_directory, filename)
            print(f"Processing file: {file_path}")

            # Read and parse the JSON file
            with open(file_path, "r") as file:
                try:
                    trip_data = json.load(file)
                    # Process the toll information as needed
                    process_trip_data(trip_data)
                except json.JSONDecodeError as e:
                    print(f"Error decoding JSON in file {file_path}: {e}")

def process_trip_data(trip_data):
    # Implement your logic to process the toll information
    # For example, you can print the details of each trip
    print("Trip Details:")
    print(f"Start Location: {trip_data['start_location']}")
    print(f"End Location: {trip_data['end_location']}")
    print(f"Toll Amount: {trip_data['toll_amount']}")
    print("\n")

input_directory = "/transformed_data.csv"

"""**Members as collaborators**
venkateshn@mapup.ai
namanjeetsingh@mapup.ai
saranshj@mapup.ai
varuna@mapup.ai
"""